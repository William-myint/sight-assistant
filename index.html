<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>DocReader AI - Camera & Multi-File Support</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <style>
        .gradient-bg { background: linear-gradient(135deg, #6366f1 0%, #a855f7 100%); }
        .glass { background: rgba(255, 255, 255, 0.9); backdrop-filter: blur(10px); }
        @keyframes pulse-ring { 0% { transform: scale(.33); opacity: 1; } 80%, 100% { opacity: 0; } }
        .recording-pulse { position: relative; }
        .recording-pulse::before {
            content: ''; display: block; width: 300%; height: 300%; box-sizing: border-box; margin-left: -100%; margin-top: -100%;
            border-radius: 45px; background-color: #ef4444; animation: pulse-ring 1.25s cubic-bezier(0.215, 0.61, 0.355, 1) infinite;
        }
        #cameraVideo { transform: scaleX(-1); } /* Mirror for selfie-feel if using front cam, though back cam is standard for docs */
    </style>
</head>
<body class="bg-slate-50 min-h-screen font-sans text-slate-900">

    <div class="max-w-4xl mx-auto px-4 py-8">
        <!-- Header -->
        <header class="text-center mb-10">
            <h1 class="text-4xl font-extrabold text-transparent bg-clip-text bg-gradient-to-r from-indigo-600 to-purple-600 mb-2">
                DocReader AI
            </h1>
            <p class="text-slate-500">Smart routing enabled. Supports Camera, Images, PDF, and Documents.</p>
        </header>

        <!-- Main Interface -->
        <main class="grid gap-6">
            
            <!-- API Key Fallback -->
            <section id="keySection" class="hidden glass p-4 rounded-xl border border-amber-200 bg-amber-50">
                <p class="text-sm text-amber-700 mb-2 font-medium">⚠️ API Key not found in environment. Please enter it manually:</p>
                <input type="password" id="manualApiKey" placeholder="Enter Gemini API Key" class="w-full px-4 py-2 rounded-lg border border-amber-300 focus:ring-2 focus:ring-indigo-500 outline-none">
            </section>

            <!-- Camera View (Hidden by default) -->
            <section id="cameraContainer" class="hidden glass p-4 rounded-2xl shadow-xl border border-white overflow-hidden text-center">
                <video id="cameraVideo" autoplay playsinline class="w-full max-w-md mx-auto rounded-lg bg-black"></video>
                <div class="mt-4 flex justify-center gap-4">
                    <button id="captureBtn" class="bg-indigo-600 text-white px-6 py-2 rounded-full font-medium hover:bg-indigo-700 transition-all">
                        Take Photo
                    </button>
                    <button id="closeCameraBtn" class="text-slate-500 hover:text-slate-700 font-medium">Cancel</button>
                </div>
                <canvas id="captureCanvas" class="hidden"></canvas>
            </section>

            <!-- Upload Section -->
            <section id="uploadSection" class="glass p-6 rounded-2xl shadow-xl border border-white">
                <div class="flex flex-col items-center justify-center border-2 border-dashed border-slate-200 rounded-xl p-8 hover:border-indigo-400 transition-colors bg-slate-50/50" id="dropzone">
                    <input type="file" id="fileInput" accept="image/*,.pdf,.docx,.txt,.epub" class="hidden">
                    
                    <div id="previewContainer" class="hidden mb-4 w-full max-w-sm text-center">
                        <img id="imagePreview" src="" alt="Preview" class="hidden rounded-lg shadow-md w-full mb-2 mx-auto">
                        <div id="filePreview" class="hidden p-8 bg-indigo-50 rounded-lg border border-indigo-100">
                            <svg xmlns="http://www.w3.org/2000/svg" class="h-16 w-16 mx-auto text-indigo-400 mb-2" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                                <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 12h6m-6 4h6m2 5H7a2 2 0 01-2-2V5a2 2 0 012-2h5.586a1 1 0 01.707.293l5.414 5.414a1 1 0 01.293.707V19a2 2 0 01-2 2z" />
                            </svg>
                            <p id="fileNameDisplay" class="font-medium text-indigo-900 truncate"></p>
                        </div>
                    </div>

                    <div id="uploadPrompt" class="text-center">
                        <div class="mb-4 text-indigo-500">
                            <svg xmlns="http://www.w3.org/2000/svg" class="h-12 w-12 mx-auto" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                                <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M7 16a4 4 0 01-.88-7.903A5 5 0 1115.9 6L16 6a5 5 0 011 9.9M15 13l-3-3m0 0l-3 3m3-3v12" />
                            </svg>
                        </div>
                        <div class="flex flex-col sm:flex-row gap-3">
                            <button onclick="document.getElementById('fileInput').click()" class="bg-indigo-600 text-white px-6 py-2 rounded-full font-medium hover:bg-indigo-700 transition-all shadow-lg shadow-indigo-200">
                                Upload File
                            </button>
                            <button id="openCameraBtn" class="bg-slate-800 text-white px-6 py-2 rounded-full font-medium hover:bg-slate-900 transition-all shadow-lg shadow-slate-200 flex items-center justify-center gap-2">
                                <svg xmlns="http://www.w3.org/2000/svg" class="h-5 w-5" viewBox="0 0 20 20" fill="currentColor">
                                    <path fill-rule="evenodd" d="M4 5a2 2 0 00-2 2v8a2 2 0 002 2h12a2 2 0 002-2V7a2 2 0 00-2-2h-1.586l-1.293-1.293A1 1 0 0012.414 3H7.586a1 1 0 00-.707.293L5.586 5H4zm6 9a3 3 0 100-6 3 3 0 000 6z" clip-rule="evenodd" />
                                </svg>
                                Camera
                            </button>
                        </div>
                        <p class="mt-4 text-xs text-slate-400">Supports JPG, PNG, PDF, DOCX, EPUB, TXT</p>
                    </div>

                    <div id="actionButtons" class="hidden mt-4 flex gap-4">
                        <button id="processBtn" class="bg-emerald-500 text-white px-8 py-2 rounded-full font-medium hover:bg-emerald-600 transition-all shadow-lg shadow-emerald-200">
                            Read Smartly
                        </button>
                        <button onclick="resetUI()" class="text-slate-500 hover:text-slate-700 font-medium">Clear</button>
                    </div>
                </div>
            </section>

            <!-- Status & Results -->
            <section id="statusSection" class="hidden glass p-6 rounded-2xl shadow-xl border border-white">
                <div id="loading" class="hidden flex flex-col items-center py-6">
                    <div class="w-10 h-10 border-4 border-indigo-200 border-t-indigo-600 rounded-full animate-spin mb-4"></div>
                    <p id="statusText" class="text-slate-600 font-medium animate-pulse">Initializing smart analysis...</p>
                </div>

                <div id="resultContent" class="hidden space-y-4">
                    <div class="flex items-center justify-between border-b border-slate-100 pb-4">
                        <div class="flex items-center gap-2">
                            <span class="flex h-3 w-3 rounded-full bg-emerald-500"></span>
                            <h2 class="font-bold text-slate-800">Transcription Result</h2>
                        </div>
                        <div id="audioVisualizer" class="flex gap-1 items-end h-6">
                            <div class="w-1 bg-indigo-500 rounded-full h-2 animate-bounce"></div>
                            <div class="w-1 bg-indigo-400 rounded-full h-4 animate-bounce" style="animation-delay: 0.1s"></div>
                            <div class="w-1 bg-indigo-600 rounded-full h-3 animate-bounce" style="animation-delay: 0.2s"></div>
                        </div>
                    </div>
                    <div class="bg-slate-900 rounded-xl p-4 overflow-x-auto">
                        <p id="textContent" class="text-emerald-400 font-mono leading-relaxed whitespace-pre-wrap"></p>
                    </div>
                    <div class="flex justify-center pt-4">
                         <button id="stopBtn" class="bg-rose-500 text-white px-6 py-2 rounded-full font-medium hover:bg-rose-600 shadow-lg shadow-rose-200">
                            Stop Playback
                         </button>
                    </div>
                </div>
            </section>

        </main>
    </div>

    <script>
        const fileInput = document.getElementById('fileInput');
        const previewImg = document.getElementById('imagePreview');
        const filePreview = document.getElementById('filePreview');
        const fileNameDisplay = document.getElementById('fileNameDisplay');
        const previewContainer = document.getElementById('previewContainer');
        const uploadPrompt = document.getElementById('uploadPrompt');
        const actionButtons = document.getElementById('actionButtons');
        const statusSection = document.getElementById('statusSection');
        const loading = document.getElementById('loading');
        const statusText = document.getElementById('statusText');
        const resultContent = document.getElementById('resultContent');
        const textDisplay = document.getElementById('textContent');
        const processBtn = document.getElementById('processBtn');
        const stopBtn = document.getElementById('stopBtn');
        const manualApiKeyInput = document.getElementById('manualApiKey');
        const keySection = document.getElementById('keySection');

        // Camera Elements
        const cameraContainer = document.getElementById('cameraContainer');
        const video = document.getElementById('cameraVideo');
        const canvas = document.getElementById('captureCanvas');
        const openCameraBtn = document.getElementById('openCameraBtn');
        const captureBtn = document.getElementById('captureBtn');
        const closeCameraBtn = document.getElementById('closeCameraBtn');

        let currentAudio = null;
        let selectedFileData = null; // Stores { mimeType, data (base64 or text), type: 'image'|'file' }
        let stream = null;

        const MODEL_PRIORITY = [
            'gemini-3-flash-preview',
            'gemini-3-pro-preview'
        ];

        let envKey = "";
        try { envKey = (typeof process !== 'undefined' && process.env.NEXT_PUBLIC_GEMINI_API_KEY) || ""; } catch (e) {}
        if (!envKey) keySection.classList.remove('hidden');

        function getActiveKey() { return envKey || manualApiKeyInput.value.trim(); }

        // Camera Logic
        openCameraBtn.addEventListener('click', async () => {
            try {
                stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: 'environment' } });
                video.srcObject = stream;
                cameraContainer.classList.remove('hidden');
                document.getElementById('uploadSection').classList.add('hidden');
            } catch (err) {
                alert("Could not access camera: " + err.message);
            }
        });

        closeCameraBtn.addEventListener('click', stopCamera);

        function stopCamera() {
            if (stream) {
                stream.getTracks().forEach(track => track.stop());
                stream = null;
            }
            cameraContainer.classList.add('hidden');
            document.getElementById('uploadSection').classList.remove('hidden');
        }

        captureBtn.addEventListener('click', () => {
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            canvas.getContext('2d').drawImage(video, 0, 0);
            const dataUrl = canvas.toDataURL('image/jpeg');
            
            setFilePreview({
                mimeType: 'image/jpeg',
                data: dataUrl.split(',')[1],
                type: 'image'
            }, dataUrl);
            
            stopCamera();
        });

        // File Input Logic
        fileInput.addEventListener('change', async function(e) {
            const file = e.target.files[0];
            if (!file) return;

            if (file.type.startsWith('image/')) {
                const reader = new FileReader();
                reader.onload = (e) => setFilePreview({
                    mimeType: file.type,
                    data: e.target.result.split(',')[1],
                    type: 'image'
                }, e.target.result);
                reader.readAsDataURL(file);
            } else {
                // Handling non-image files
                setFilePreview({
                    mimeType: file.type || 'application/octet-stream',
                    name: file.name,
                    file: file, // Keep reference for later extraction if needed
                    type: 'file'
                });
            }
        });

        function setFilePreview(fileObj, visualUrl = null) {
            selectedFileData = fileObj;
            uploadPrompt.classList.add('hidden');
            previewContainer.classList.remove('hidden');
            actionButtons.classList.remove('hidden');

            if (fileObj.type === 'image') {
                previewImg.src = visualUrl;
                previewImg.classList.remove('hidden');
                filePreview.classList.add('hidden');
            } else {
                previewImg.classList.add('hidden');
                filePreview.classList.remove('hidden');
                fileNameDisplay.innerText = fileObj.name || "Document File";
            }
        }

        function resetUI() {
            fileInput.value = '';
            selectedFileData = null;
            previewImg.src = '';
            previewContainer.classList.add('hidden');
            uploadPrompt.classList.remove('hidden');
            actionButtons.classList.add('hidden');
            statusSection.classList.add('hidden');
            stopAudio();
        }

        function stopAudio() {
            if (currentAudio) {
                currentAudio.pause();
                currentAudio = null;
            }
        }

        stopBtn.addEventListener('click', stopAudio);

        async function apiRequest(url, payload, retries = 2) {
            const key = getActiveKey();
            if (!key) throw new Error('API Key missing.');

            for (let i = 0; i < retries; i++) {
                try {
                    const response = await fetch(`${url}?key=${key}`, {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json' },
                        body: JSON.stringify(payload)
                    });
                    if (!response.ok) {
                        const error = await response.json();
                        if ([404, 403, 400].includes(response.status)) throw new Error('MODEL_UNAVAILABLE');
                        throw new Error(error.error?.message || 'API request failed');
                    }
                    return await response.json();
                } catch (err) {
                    if (err.message === 'MODEL_UNAVAILABLE') throw err;
                    if (i === retries - 1) throw err;
                    await new Promise(res => setTimeout(res, 500));
                }
            }
        }

        processBtn.addEventListener('click', async () => {
            if (!selectedFileData) return;

            const key = getActiveKey();
            if (!key) {
                alert("Please enter your Gemini API key.");
                keySection.scrollIntoView({ behavior: 'smooth' });
                return;
            }

            statusSection.classList.remove('hidden');
            loading.classList.remove('hidden');
            resultContent.classList.add('hidden');
            processBtn.disabled = true;

            try {
                let script = "";
                let parts = [];

                if (selectedFileData.type === 'image') {
                    parts = [
                        { text: "Transcribe all visible text from this document. Output ONLY raw text." },
                        { inlineData: { mimeType: selectedFileData.mimeType, data: selectedFileData.data } }
                    ];
                } else {
                    // For non-image files, we use a different strategy.
                    // Gemini 1.5+ supports PDF directly as inlineData or via text extraction for smaller files.
                    // For TXT/small docs, we'll try reading as text first.
                    if (selectedFileData.mimeType === 'text/plain') {
                        const text = await selectedFileData.file.text();
                        parts = [{ text: `Transcribe/Read this content and provide a clean version: \n\n ${text}` }];
                    } else {
                        // For PDF/DOCX, we send the file as inlineData (Gemini 1.5 supports up to 20MB PDFs)
                        const reader = new FileReader();
                        const base64Promise = new Promise(resolve => {
                            reader.onload = () => resolve(reader.result.split(',')[1]);
                            reader.readAsDataURL(selectedFileData.file);
                        });
                        const base64 = await base64Promise;
                        parts = [
                            { text: "Transcribe all text content from this document. Output ONLY raw text." },
                            { inlineData: { mimeType: selectedFileData.mimeType, data: base64 } }
                        ];
                    }
                }

                // SMART ROUTING
                for (const model of MODEL_PRIORITY) {
                    try {
                        statusText.innerText = `Analyzing with ${model}...`;
                        const res = await apiRequest(
                            `https://generativelanguage.googleapis.com/v1beta/models/${model}:generateContent`,
                            { contents: [{ parts }] },
                            1
                        );
                        script = res.candidates?.[0]?.content?.parts?.[0]?.text;
                        if (script) break;
                    } catch (e) { continue; }
                }

                if (!script) throw new Error("Could not extract text from this file with available models.");

                textDisplay.innerText = script;

                // TTS
                statusText.innerText = "Generating voice...";
                const ttsModels = ['gemini-2.5-flash-preview-tts', 'gemini-2.5-pro-preview-tts'];
                let ttsResult = null;

                for (const ttsModel of ttsModels) {
                    try {
                        ttsResult = await apiRequest(
                            `https://generativelanguage.googleapis.com/v1beta/models/${ttsModel}:generateContent`,
                            {
                                contents: [{ parts: [{ text: script }] }],
                                generationConfig: {
                                    responseModalities: ["AUDIO"],
                                    speechConfig: { voiceConfig: { prebuiltVoiceConfig: { voiceName: "Aoede" } } }
                                }
                            },
                            1
                        );
                        if (ttsResult) break;
                    } catch (e) { continue; }
                }

                if (!ttsResult) throw new Error("Voice generation failed.");

                const pcmData = ttsResult.candidates[0].content.parts[0].inlineData.data;
                const audioBlob = pcmToWav(pcmData, 24000);
                const audioUrl = URL.createObjectURL(audioBlob);

                loading.classList.add('hidden');
                resultContent.classList.remove('hidden');

                stopAudio();
                currentAudio = new Audio(audioUrl);
                currentAudio.play();

            } catch (error) {
                alert("Error: " + error.message);
                loading.classList.add('hidden');
            } finally {
                processBtn.disabled = false;
            }
        });

        function pcmToWav(base64Pcm, sampleRate) {
            const pcmBuffer = Uint8Array.from(atob(base64Pcm), c => c.charCodeAt(0)).buffer;
            const wavHeader = new ArrayBuffer(44);
            const view = new DataView(wavHeader);
            view.setUint32(0, 0x52494646, false);
            view.setUint32(4, 36 + pcmBuffer.byteLength, true);
            view.setUint32(8, 0x57415645, false);
            view.setUint32(12, 0x666d7420, false);
            view.setUint32(16, 16, true);
            view.setUint16(20, 1, true);
            view.setUint16(22, 1, true);
            view.setUint32(24, sampleRate, true);
            view.setUint32(28, sampleRate * 2, true);
            view.setUint16(32, 2, true);
            view.setUint16(34, 16, true);
            view.setUint32(36, 0x64617461, false);
            view.setUint32(40, pcmBuffer.byteLength, true);
            return new Blob([wavHeader, pcmBuffer], { type: 'audio/wav' });
        }
    </script>
</body>
</html>
